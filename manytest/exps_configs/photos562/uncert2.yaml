name: "uncert2_562_train" # name of group in wandb
project: "actsrf"
place_names: ["room_0", "room_1", "room_2", "office_0", "office_1", "office_2", "office_3", "office_4"]
sequences: ["Sequence_1", "Sequence_2"]
scene_dir: "/mnt/hdd8/Datasets/Replica/semantic_info/"
dataset_dir: "/mnt/hdd8/Datasets/Replica/"
store_result: # where to store results
  semantic_ngp: "/mnt/hdd8/skorokhodov_vs/results/semantic_ngp_results/"
  torch_ngp: "/mnt/hdd8/skorokhodov_vs/results/torch-ngp_results"
  semantic_nerf: "/mnt/hdd8/skorokhodov_vs/results/semantic_nerf_results"
start: # start script
  semantic_ngp: "/home/skorokhodov_vs/nerf/from_laba/ngp_with_semantic_nerf/main_nerf.py"
  torch_ngp: "/home/skorokhodov_vs/nerf/from_laba/torch-ngp/main_nerf.py"
  semantic_nerf: "/home/skorokhodov_vs/nerf/from_laba/semantic_nerf/train_SSR_main_time_measure.py"

convert_script_path: "/home/skorokhodov_vs/nerf/from_laba/ngp_with_semantic_nerf/scripts/replica2nerf.py" # script to convert poses to nerf format
split_script_path: "/home/skorokhodov_vs/nerf/from_laba/ngp_with_semantic_nerf/scripts/make_split.py"
continue_on_fail: True
gpu: [0, 1, 2]

experiments:
### EXPERIMENT 1 ###
  -
    w: 640
    h: 480
    place: "room_0"
    sequence: "Sequence_1"
    need_transforms: True
    
    # total: 900 photos
    eval_ratio: 0.125   # 112
    train_ratio: 0.625
    holdout_ratio: 0
    test_ratio: 0.250   # 225

    common: 
      video_mode: 2
      video_interval: 200
      lr: 0.003
      bound: 5.0
      scale: 0.5
      max_ray_batch: 2048
      # parameters for active learning
      active_learning_interval: 1550
      active_learning_num: 10

    semantic_ngp:
      - 
        use_semantic: True
        lambd: 0.005
        omega: 0.0      

      - 
        use_semantic: True
        use_semantic_uncert: True
        lambd: 0.05
        omega: 0.0

      - 
        use_uncert: True
        use_semantic: True
        use_semantic_uncert: True
        lambd: 0.05
        omega: 0.00001

### EXPERIMENT 2 ###
  -
    w: 640
    h: 480
    place: "office_0"
    sequence: "Sequence_1"
    need_transforms: True
    
    # total: 900 photos
    eval_ratio: 0.125   # 112
    train_ratio: 0.625
    holdout_ratio: 0
    test_ratio: 0.250   # 225

    common: 
      video_mode: 2
      video_interval: 200
      lr: 0.003
      bound: 5.0
      scale: 0.5
      max_ray_batch: 2048
      # parameters for active learning
      active_learning_interval: 1550
      active_learning_num: 10

    semantic_ngp:
      - 
        use_semantic: True
        lambd: 0.005
        omega: 0.0      

      - 
        use_semantic: True
        use_semantic_uncert: True
        lambd: 0.05
        omega: 0.0

      - 
        use_uncert: True
        use_semantic: True
        use_semantic_uncert: True
        lambd: 0.05
        omega: 0.00001

### EXPERIMENT 3 ###
  -
    w: 640
    h: 480
    place: "room_1"
    sequence: "Sequence_1"
    need_transforms: True
    
    # total: 900 photos
    eval_ratio: 0.125   # 112
    train_ratio: 0.625
    holdout_ratio: 0
    test_ratio: 0.250   # 225

    common: 
      video_mode: 2
      video_interval: 200
      lr: 0.003
      bound: 5.0
      scale: 0.5
      max_ray_batch: 2048
      # parameters for active learning
      active_learning_interval: 1550
      active_learning_num: 10

    semantic_ngp:
      - 
        use_semantic: True
        lambd: 0.005
        omega: 0.0      

      - 
        use_semantic: True
        use_semantic_uncert: True
        lambd: 0.05
        omega: 0.0

      - 
        use_uncert: True
        use_semantic: True
        use_semantic_uncert: True
        lambd: 0.05
        omega: 0.00001
